{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41813645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time \n",
    "import os\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "\n",
    "data_folder_path = '../'\n",
    "raw_data_path = \"../raw_data\"\n",
    "storage_path = \"../database_storage\"\n",
    "daily_path = \"../daily\"\n",
    "DTBS_path = os.path.join(storage_path, \"DTBS.pkl\")\n",
    "DCBS_path = os.path.join(storage_path, \"DCBS.pkl\")\n",
    "# re-open\n",
    "with open(DCBS_path, 'rb') as f:  \n",
    "    DCBS = pickle.load(f)\n",
    "# re-open\n",
    "with open(DTBS_path, 'rb') as f:  \n",
    "    DTBS = pickle.load(f)\n",
    "\n",
    "# 本文件的主要作用是读取DCBS.pkl，并将其转化成适合处理的DataFrame形式存储起来，这个运行时间大概1分钟左右，需要更新大数据库DTBS_DataFrame.pkl时手动运行此文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab98ed0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      bond_code        date    cpr      dp    bl     trt  \\\n",
      "id                                                                         \n",
      "110088.SH,2017-01-03  110088.SH  2017-01-03    NaN     NaN   NaN     NaN   \n",
      "110088.SH,2017-01-04  110088.SH  2017-01-04    NaN     NaN   NaN     NaN   \n",
      "110088.SH,2017-01-05  110088.SH  2017-01-05    NaN     NaN   NaN     NaN   \n",
      "110088.SH,2017-01-06  110088.SH  2017-01-06    NaN     NaN   NaN     NaN   \n",
      "110088.SH,2017-01-09  110088.SH  2017-01-09    NaN     NaN   NaN     NaN   \n",
      "...                         ...         ...    ...     ...   ...     ...   \n",
      "123214.SZ,2023-08-15  123214.SZ  2023-08-15    NaN     NaN   NaN     NaN   \n",
      "123214.SZ,2023-08-16  123214.SZ  2023-08-16    NaN     NaN   NaN     NaN   \n",
      "123214.SZ,2023-08-17  123214.SZ  2023-08-17    NaN     NaN   NaN     NaN   \n",
      "123214.SZ,2023-08-18  123214.SZ  2023-08-18  31.67  122.00  4.55   21.26   \n",
      "123214.SZ,2023-08-21  123214.SZ  2023-08-21  31.31  122.65  4.55  111.86   \n",
      "\n",
      "                       ytm     yl      dl  ia  ...  qsn  xxn        csv  \\\n",
      "id                                             ...                        \n",
      "110088.SH,2017-01-03   NaN    NaN  999.00   0  ...  0.0  0.0   0.000000   \n",
      "110088.SH,2017-01-04   NaN    NaN  999.00   0  ...  0.0  0.0   0.000000   \n",
      "110088.SH,2017-01-05   NaN    NaN  999.00   0  ...  0.0  0.0   0.000000   \n",
      "110088.SH,2017-01-06   NaN    NaN  999.00   0  ...  0.0  0.0   0.000000   \n",
      "110088.SH,2017-01-09   NaN    NaN  999.00   0  ...  0.0  0.0   0.000000   \n",
      "...                    ...    ...     ...  ..  ...  ...  ...        ...   \n",
      "123214.SZ,2023-08-15   NaN    NaN  999.00   0  ...  NaN  NaN   0.000000   \n",
      "123214.SZ,2023-08-16   NaN    NaN  999.00   0  ...  NaN  NaN   0.000000   \n",
      "123214.SZ,2023-08-17   NaN    NaN  999.00   0  ...  NaN  NaN   0.000000   \n",
      "123214.SZ,2023-08-18 -0.52  5.953  153.67   1  ...  NaN  NaN  92.653673   \n",
      "123214.SZ,2023-08-21 -0.62  5.945  153.96   1  ...  NaN  NaN  93.403298   \n",
      "\n",
      "                           cz         pd  qs15  qs30  xx15  xx30   hs  \n",
      "id                                                                     \n",
      "110088.SH,2017-01-03   0.0000   0.000000   0.0   0.0   0.0   0.0  NaN  \n",
      "110088.SH,2017-01-04   0.0000   0.000000   0.0   0.0   0.0   0.0  NaN  \n",
      "110088.SH,2017-01-05   0.0000   0.000000   0.0   0.0   0.0   0.0  NaN  \n",
      "110088.SH,2017-01-06   0.0000   0.000000   0.0   0.0   0.0   0.0  NaN  \n",
      "110088.SH,2017-01-09   0.0000   0.000000   0.0   0.0   0.0   0.0  NaN  \n",
      "...                       ...        ...   ...   ...   ...   ...  ...  \n",
      "123214.SZ,2023-08-15   0.0000   0.000000   0.0   0.0   NaN   NaN  0.0  \n",
      "123214.SZ,2023-08-16   0.0000   0.000000   0.0   0.0   NaN   NaN  0.0  \n",
      "123214.SZ,2023-08-17   0.0000   0.000000   0.0   0.0   NaN   NaN  0.0  \n",
      "123214.SZ,2023-08-18  73.7734  25.592250   NaN   NaN   NaN   NaN  0.0  \n",
      "123214.SZ,2023-08-21  73.8599  26.460093   0.0   0.0   0.0   0.0  0.0  \n",
      "\n",
      "[1329112 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "DTBS_A = DTBS['A']\n",
    "\n",
    "# 对于三级字典，可以将前两级组成MultiIndex,然后使用pandas的from_dict创建Dataframe\n",
    "A_newDict = {(i, j): DTBS_A[i][j] for i in DTBS_A.keys() for j in DTBS_A[i].keys()}\n",
    "\n",
    "A_DataFrame = pd.DataFrame.from_dict(A_newDict,orient='index')\n",
    "\n",
    "\n",
    "# 重设DataFrame的索引，并将新增的两列改名，再重设索引\n",
    "A_DataFrame = A_DataFrame.reset_index().copy()\n",
    "A_DataFrame.rename(columns={'level_0' : 'bond_code','level_1' : 'date'},inplace=True)\n",
    "\n",
    "A_DataFrame['id'] = A_DataFrame['bond_code'] + ',' + A_DataFrame['date']\n",
    "\n",
    "A_DataFrame.set_index('id', inplace=True)\n",
    "\n",
    "print(A_DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f124451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_DataFrame[A_DataFrame['ia'] == 1].to_csv('database_ByZCG\\\\观察.csv',encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c0a2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bond_code     127086.SZ\n",
      "date         2023-07-19\n",
      "cpr               27.95\n",
      "dp               133.42\n",
      "bl                 31.6\n",
      "trt                6.33\n",
      "ytm               -2.89\n",
      "yl                5.904\n",
      "dl               161.37\n",
      "ia                    1\n",
      "qs                    0\n",
      "xx                    0\n",
      "csp               11.46\n",
      "qsn                 NaN\n",
      "xxn                 NaN\n",
      "csv          104.275742\n",
      "cz              92.4164\n",
      "pd            12.832508\n",
      "qs15                0.0\n",
      "qs30                0.0\n",
      "xx15                0.0\n",
      "xx30                0.0\n",
      "hs                  0.0\n",
      "Name: 127086.SZ,2023-07-19, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(A_DataFrame.loc['127086.SZ,2023-07-19'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4d439c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      bond_code        date  cpr  dp  bl  trt  ytm  yl     dl  \\\n",
      "id                                                                              \n",
      "110088.SH,2017-01-03  110088.SH  2017-01-03  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-04  110088.SH  2017-01-04  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-05  110088.SH  2017-01-05  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-06  110088.SH  2017-01-06  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-09  110088.SH  2017-01-09  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-10  110088.SH  2017-01-10  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-11  110088.SH  2017-01-11  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-12  110088.SH  2017-01-12  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-13  110088.SH  2017-01-13  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-16  110088.SH  2017-01-16  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-17  110088.SH  2017-01-17  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-18  110088.SH  2017-01-18  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-19  110088.SH  2017-01-19  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-20  110088.SH  2017-01-20  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-23  110088.SH  2017-01-23  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-24  110088.SH  2017-01-24  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-25  110088.SH  2017-01-25  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-01-26  110088.SH  2017-01-26  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-02-03  110088.SH  2017-02-03  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "110088.SH,2017-02-06  110088.SH  2017-02-06  NaN NaN NaN  NaN  NaN NaN  999.0   \n",
      "\n",
      "                      ia  ...  qsn  xxn  csv   cz   pd  qs15  qs30  xx15  \\\n",
      "id                        ...                                              \n",
      "110088.SH,2017-01-03   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-04   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-05   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-06   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-09   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-10   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-11   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-12   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-13   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-16   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-17   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-18   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-19   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-20   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-23   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-24   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-25   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-01-26   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-02-03   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "110088.SH,2017-02-06   0  ...  0.0  0.0  0.0  0.0  0.0   0.0   0.0   0.0   \n",
      "\n",
      "                      xx30  hs  \n",
      "id                              \n",
      "110088.SH,2017-01-03   0.0 NaN  \n",
      "110088.SH,2017-01-04   0.0 NaN  \n",
      "110088.SH,2017-01-05   0.0 NaN  \n",
      "110088.SH,2017-01-06   0.0 NaN  \n",
      "110088.SH,2017-01-09   0.0 NaN  \n",
      "110088.SH,2017-01-10   0.0 NaN  \n",
      "110088.SH,2017-01-11   0.0 NaN  \n",
      "110088.SH,2017-01-12   0.0 NaN  \n",
      "110088.SH,2017-01-13   0.0 NaN  \n",
      "110088.SH,2017-01-16   0.0 NaN  \n",
      "110088.SH,2017-01-17   0.0 NaN  \n",
      "110088.SH,2017-01-18   0.0 NaN  \n",
      "110088.SH,2017-01-19   0.0 NaN  \n",
      "110088.SH,2017-01-20   0.0 NaN  \n",
      "110088.SH,2017-01-23   0.0 NaN  \n",
      "110088.SH,2017-01-24   0.0 NaN  \n",
      "110088.SH,2017-01-25   0.0 NaN  \n",
      "110088.SH,2017-01-26   0.0 NaN  \n",
      "110088.SH,2017-02-03   0.0 NaN  \n",
      "110088.SH,2017-02-06   0.0 NaN  \n",
      "\n",
      "[20 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "A_ConvertibleBondTimeSeries = A_DataFrame.copy()\n",
    "print(A_ConvertibleBondTimeSeries.head(20))\n",
    "\n",
    "# 保存到新的数据库中，分别存储成pkl格式和csv格式\n",
    "f_save = open('database_ByZCG\\\\A_ConvertibleBondTimeSeries_DataFrame.pkl', 'wb')\n",
    "pickle.dump(A_ConvertibleBondTimeSeries, f_save)\n",
    "f_save.close()\n",
    "\n",
    "A_ConvertibleBondTimeSeries.to_csv('database_ByZCG\\\\A_ConvertibleBondTimeSeries_DataFrame.csv',encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0079f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTBS_B = DTBS['B']\n",
    "DTBS_C = DTBS['C']\n",
    "DTBS_D = DTBS['D']\n",
    "DTBS_E = DTBS['E']\n",
    "DTBS_F = DTBS['F']\n",
    "DTBS_G = DTBS['G']\n",
    "# print('B区：\\n', DTBS_B)\n",
    "# print('C区：\\n', DTBS_C)\n",
    "# print('D区：\\n', DTBS_D)\n",
    "# print('E区：\\n', DTBS_E)\n",
    "# print('F区：\\n', DTBS_F)\n",
    "# print('G区：\\n', DTBS_G)\n",
    "\n",
    "\n",
    "# 将B区格式化为DataFrame\n",
    "B_DataFrame = pd.DataFrame.from_dict(DTBS_B,orient='index')\n",
    "B_DataFrame.reset_index(inplace=True)\n",
    "B_DataFrame.rename(columns={'index' : 'bond_code'},inplace=True)\n",
    "\n",
    "\n",
    "# 将C区格式化为DataFrame\n",
    "C_DataFrame = pd.DataFrame.from_dict(DTBS_C,orient='index')\n",
    "C_DataFrame = pd.DataFrame(C_DataFrame.values.T, index=C_DataFrame.columns, columns=C_DataFrame.index)\n",
    "C_DataFrame.reset_index(inplace=True)\n",
    "C_DataFrame.rename(columns={'index' : 'date'},inplace=True)\n",
    "\n",
    "\n",
    "# 将D区格式化为DataFrame\n",
    "D_DataFrame = pd.DataFrame(DTBS_D['day'],columns=['date'])\n",
    "mon_list = DTBS_D['mon']\n",
    "tue_list = DTBS_D['tue']\n",
    "wed_list = DTBS_D['wed']\n",
    "thu_list = DTBS_D['thu']\n",
    "fri_list = DTBS_D['fri']\n",
    "def get_today_is_which_day(x):\n",
    "    if x in mon_list:\n",
    "        return 'mon'\n",
    "    elif x in tue_list:\n",
    "        return 'tue'\n",
    "    elif x in wed_list:\n",
    "        return 'wed'\n",
    "    elif x in thu_list:\n",
    "        return 'thu'\n",
    "    else:\n",
    "        return 'fri'\n",
    "D_DataFrame['which_day'] = D_DataFrame['date'].apply(get_today_is_which_day)\n",
    "\n",
    "\n",
    "# 将E区格式化为DataFrame\n",
    "# 对于三级字典，可以将前两级组成MultiIndex,然后使用pandas的from_dict创建Dataframe\n",
    "E_newDict = {(i, j): DTBS_E[i][j] for i in DTBS_E.keys() for j in DTBS_E[i].keys()}\n",
    "\n",
    "E_DataFrame = pd.DataFrame.from_dict(E_newDict,orient='index')\n",
    "\n",
    "# 重设DataFrame的索引，并将新增的两列改名，再重设索引\n",
    "E_DataFrame = E_DataFrame.reset_index().copy()\n",
    "E_DataFrame.rename(columns={'level_0' : 'stock_code','level_1' : 'date'},inplace=True)\n",
    "E_DataFrame['id'] = E_DataFrame['stock_code'] + ',' + E_DataFrame['date']\n",
    "E_DataFrame.set_index('id', inplace=True)\n",
    "\n",
    "\n",
    "# 将F区格式化为DataFrame\n",
    "# 对于三级字典，可以将前两级组成MultiIndex,然后使用pandas的from_dict创建Dataframe\n",
    "F_newDict = {(i, j): DTBS_F[i][j] for i in DTBS_F.keys() for j in DTBS_F[i].keys()}\n",
    "\n",
    "F_DataFrame = pd.DataFrame.from_dict(F_newDict,orient='index')\n",
    "\n",
    "# 重设DataFrame的索引，并将新增的两列改名，再重设索引\n",
    "F_DataFrame = F_DataFrame.reset_index().copy()\n",
    "F_DataFrame.rename(columns={'level_0' : 'stock_code','level_1' : 'quarter'},inplace=True)\n",
    "\n",
    "\n",
    "# 将G区格式化为DataFrame\n",
    "G_DataFrame = pd.DataFrame.from_dict(DTBS_G,orient='index')\n",
    "G_DataFrame.reset_index(inplace=True)\n",
    "G_DataFrame.rename(columns={'index' : 'stock_code'},inplace=True)\n",
    "# DTBS的G区中的数据没有清洗干净\n",
    "G_DataFrame = G_DataFrame[G_DataFrame['stock_code'].apply(len) == 9].copy()\n",
    "G_DataFrame.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# print(B_DataFrame)\n",
    "# print(C_DataFrame)\n",
    "# print(D_DataFrame)\n",
    "# print(E_DataFrame)\n",
    "# print(F_DataFrame.loc[F_DataFrame['quarter']=='2023-03'])\n",
    "# print(G_DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3ca09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTBS_DataFrame = {'A' : A_DataFrame,\n",
    "                  'B' : B_DataFrame,\n",
    "                  'C' : C_DataFrame,\n",
    "                  'D' : D_DataFrame,\n",
    "                  'E' : E_DataFrame,\n",
    "                  'F' : F_DataFrame,\n",
    "                  'G' : G_DataFrame}\n",
    "\n",
    "# 保存到新的数据库中，分别存储成pkl格式和csv格式\n",
    "f_save = open('database_ByZCG\\\\DTBS_DataFrame.pkl', 'wb')\n",
    "pickle.dump(DTBS_DataFrame, f_save)\n",
    "f_save.close()\n",
    "\n",
    "B_DataFrame.to_csv('database_ByZCG\\\\B_ConvertibleBondLongTermInformation_DataFrame.csv',encoding=\"utf_8_sig\")\n",
    "C_DataFrame.to_csv('database_ByZCG\\\\C_MarketInformation_DataFrame.csv',encoding=\"utf_8_sig\")\n",
    "D_DataFrame.to_csv('database_ByZCG\\\\D_DateInformation_DataFrame.csv',encoding=\"utf_8_sig\")\n",
    "E_DataFrame.to_csv('database_ByZCG\\\\E_StockTimeSeries_DataFrame.csv',encoding=\"utf_8_sig\")\n",
    "F_DataFrame.to_csv('database_ByZCG\\\\F_StockQuarterInformation_DataFrame.csv',encoding=\"utf_8_sig\")\n",
    "G_DataFrame.to_csv('database_ByZCG\\\\G_StockLongTermInformation_DataFrame.csv',encoding=\"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9310bd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cpr': 42.16,\n",
       " 'dp': 118.898,\n",
       " 'dl': 161.058,\n",
       " 'ytm': -2.25,\n",
       " 'bl': 9.865,\n",
       " 'trt': 0.7,\n",
       " 'yl': 2.167,\n",
       " 'csp': 9.96,\n",
       " 'ia': 1,\n",
       " 'xx': 0,\n",
       " 'hs': 0,\n",
       " 'csv': 83.63453815261043,\n",
       " 'qs': 0,\n",
       " 'qs15': 0,\n",
       " 'qs30': 0,\n",
       " 'xx15': 0,\n",
       " 'xx30': 0,\n",
       " 'cz': 106.3397,\n",
       " 'pd': -21.351538369385626}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DTBS['A']['113545.SH']['2023-08-15']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68b3892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa620eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
